
Implementation Specs for the Indexer:

For the implementation of the indexer, I will implement the functions below in the indexer.c file:

static void parseArgs(const int argc, char* argv[], char** pageDirectory, char** indexFilename);
static index_t* indexBuild(char* pageDirectory);
static bool str2int(const char string[], int *number);
static void indexPage(index_t* index, webpage_t* webpage, int docID);

Below are the descriptions for each of the functions above.
These functions are also described at the beginning of the indexer file,
and their documentation (in VS code) can be read by pressing on them.

/* ******************* parseArgs ************************************** */
/* This function validates command-line arguments.
 *
 * We assume:
 *   Caller passes the parameters of main(), and two non-NULL string pointers 
 *   to store the pageDirectory and indexFilename parameters.
 *  
 * We return:
 *   Nothing (void).
 *   
 * We guarantee:
 *   If the provided page directory is not a valid directory marked for crawling, 
 *   or the provided index filename is not a valid path to a file which can be 
 *   opened for writing, we print an appropriate error message and exit the program.
 *   Otherwise, we malloc memory for *pageDirectory and *indexFilename
 *   to store the valid parameters.
 *   
 * Caller is responsible for:
 *   Later free'ing the memory allocated for pageDirectory and indexFilename.
 */


/* ******************* indexBuild ************************************** */
/* This function makes an index for a crawling directory.
 *
 * We assume:
 *   Caller provides a valid pageDirectory marked for crawling,
 *   which has been validated by parseArgs.
 * 
 * We return:
 *   The pointer to an index for all the files in pageDirectory. 
 *   
 * We guarantee:
 *   All words in the index are normalized (converted to lowercase),
 *   and words with fewer than three characters are not added to the index.
 * 
 * Caller is responsible for:
 *   Later calling index_delete, and freeing the memory malloc'd
 *   for pageDirectory.
 */


/* ******************* str2int ************************************** */
/* This function converts a string into an integer.
 *
 * We assume:
 *   Caller provides a valid string string[] 
 *   and a valid pointer to an integer *number.
 * 
 * We return:
 *   If the string can be casted to an integer, the function returns 
 *   true and assigns the resulting integer to the pointer *number
 *   provided by the caller.
 *   Otherwise, the function returns false.
 *  
 * Caller is responsible for:
 *   Providing a string which contains one and only one integer,
 *   and nothing else.
 */

/* ******************* indexPage ************************************** */
/* This is a helper-function called by indexBuild which 
 * given an index, webpage, and docID adds all the appropriate words 
 * contained in the webpage to the index.
 */


Testing plan for the Indexer:

In order to test the Indexer, I will run an executable program testing.sh, 
and save its output in a file testing.out.
All of this will be automatically executed by running "make test."

NOTE: After running "make test" you must run "make clean" in order to
remove the directory created to store all the index files. Otherwise,
if you run "make test" again you will get an error for calling "mkdir"
on an already existing directory.

The executable program testing.sh first tests a variety of invalid 
command-line arguments in order to test parseArgs, and then compares
the sorted versions of files generated by the indexer and indextest
to verify that they are equal. All of the programs are run under
Valgrind to ensure the absence of memory leaks, and the process is
repeated for the letters, toscrape, and wikipedia crawling directories.

The testing.out file is already available in the indexer directory.